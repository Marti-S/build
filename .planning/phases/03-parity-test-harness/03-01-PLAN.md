---
phase: 03-parity-test-harness
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/parity-test.js
  - package.json
  - MAINTAINERS.md
  - .gitignore
autonomous: true

must_haves:
  truths:
    - "Maintainer can run a single command to compare Codex vs ClaudeCode artifacts and see pass/fail status"
    - "Parity report lists which .planning artifacts differ and where logs live"
    - "Parity runs execute in isolated workspaces without modifying primary repo artifacts"
  artifacts:
    - path: "scripts/parity-test.js"
      provides: "Parity harness that provisions workspaces, runs CLIs, and compares artifacts"
    - path: "package.json"
      provides: "npm script entrypoint for parity test"
    - path: "MAINTAINERS.md"
      provides: "Maintainer instructions for running parity tests"
    - path: ".gitignore"
      provides: "Ignore parity workspaces and reports"
  key_links:
    - from: "package.json"
      to: "scripts/parity-test.js"
      via: "npm run test:parity"
      pattern: "test:parity"
    - from: "scripts/parity-test.js"
      to: ".planning/parity"
      via: "report and log output"
      pattern: "\.planning/parity"
    - from: "scripts/parity-test.js"
      to: "bin/install.js"
      via: "workspace installs"
      pattern: "bin/install.js"
    - from: "scripts/parity-test.js"
      to: ".planning/phases/<phase>-*"
      via: "artifact diff"
      pattern: "\.planning/phases"
---

<objective>
Ship an automated parity harness that mirrors the ClaudeCode suite for Codex vs ClaudeCode artifact comparison.

Purpose: Give maintainers a single command to verify parity and pinpoint artifact diffs.
Output: Parity runner script, npm entrypoint, and maintainer documentation.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-parity-test-harness/03-CONTEXT.md
@.planning/phases/03-parity-test-harness/03-RESEARCH.md
@.planning/parity/02-parity-report.md

@package.json
@bin/install.js
@MAINTAINERS.md
@.gitignore
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement parity runner script</name>
  <files>scripts/parity-test.js</files>
  <action>
Create a Node.js parity runner that mirrors the ClaudeCode parity suite 1:1 and compares Codex vs ClaudeCode artifacts.

- Implement `scripts/parity-test.js` using Node built-ins only (`fs`, `path`, `os`, `child_process`, `crypto`).
- Follow the command coverage, ordering, and report fields defined in `.planning/parity/opencode-run/.planning/phases/03-parity-test-harness/03-01-PLAN.md`. Do not invent new commands or alter ordering.
- CLI flags:
  - `--baseline` (`claude` or `opencode`, default `claude`) to pick baseline installer flag.
  - `--phase` (default `98`) and fallback to `98.1`, `98.2` if that phase already exists in either workspace.
  - `--report` optional path; default `.planning/parity/parity-report.md`.
  - `--keep-workspaces` to skip workspace cleanup.
- Require env vars `GSD_PARITY_CODEX_CMD` and `GSD_PARITY_BASELINE_CMD` for non-interactive CLI commands; print a clear error and exit non-zero if missing.
- Workspace flow:
  - Create `.planning/parity/` and fresh `codex-run` + `baseline-run` subdirectories (remove prior unless `--keep-workspaces`).
  - Copy tracked repo files into each workspace using `git ls-files` to avoid `.git` and untracked noise.
  - Run installs in each workspace: Codex `node bin/install.js --codex --local`; baseline `node bin/install.js --claude --local` or `--opencode --local` based on `--baseline`.
  - Run `/gsd:plan-phase <phase> --skip-research --skip-verify` then `/gsd:execute-phase <phase>` in each workspace using env command templates; capture stdout/stderr logs under `.planning/parity/`.
- Artifact diff:
  - Compare `.planning/phases/<phase>-*/` between codex and baseline.
  - Normalize lines that cause time-based noise (`^completed:`, `^duration:`, `^Started:`, `^Completed:`, `^Last updated:`) and trim trailing whitespace before diffing.
  - Report missing/extra files and include a short diff summary per file (first ~20 differing lines).
- Exit status: `0` when parity passes, `1` when diffs/missing files exist, `2` on setup/run errors.
  </action>
  <verify>`node scripts/parity-test.js --help` prints usage and required env vars.</verify>
  <done>Parity runner builds workspaces, runs Codex + baseline flows, writes a report, and exits with pass/fail status.</done>
</task>

<task type="auto">
  <name>Task 2: Wire parity command and maintainer docs</name>
  <files>package.json; MAINTAINERS.md; .gitignore</files>
  <action>
Expose the parity runner via npm and document how maintainers run and interpret it.

- Add `"test:parity": "node scripts/parity-test.js"` to `package.json` scripts.
- Update `MAINTAINERS.md` with a "Parity Tests" section that covers:
  - Prereqs: Codex CLI and Claude/OpenCode CLI installed and authenticated.
  - Env vars: `GSD_PARITY_CODEX_CMD`, `GSD_PARITY_BASELINE_CMD` with example values.
  - Command: `npm run test:parity` and optional `--baseline opencode`, `--report`, `--keep-workspaces`.
  - Report location and how to interpret pass/fail exit codes and log paths.
- Add `.planning/parity/` to `.gitignore` so workspaces and reports remain untracked.
  </action>
  <verify>`npm run test:parity -- --help` prints usage and `MAINTAINERS.md` includes the new section.</verify>
  <done>Maintainers have a single command with documented prerequisites, env vars, and report outputs.</done>
</task>

</tasks>

<verification>
- `npm run test:parity -- --help` prints parity runner usage and required env vars.
- `MAINTAINERS.md` documents prerequisites, env vars, command, report path, and exit codes.
- `.gitignore` ignores `.planning/parity/`.
</verification>

<success_criteria>
- Parity runner exists and produces pass/fail output with a detailed report.
- One command (`npm run test:parity`) runs the parity suite in isolated workspaces.
- Reports identify which artifacts diverged and where logs are stored.
</success_criteria>

<output>
After completion, create `.planning/phases/03-parity-test-harness/03-01-SUMMARY.md`
</output>
